{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a basic classification problem example using AWS SageMaker's XGBoost Algorithm to predict whether a person makes <= 50K per year or > 50K per year based on census data. It is modeled after the AWS tutorial found here:\n",
    "https://docs.aws.amazon.com/sagemaker/latest/dg/gs-console.html\n",
    "\n",
    "The census data set can be found here:\n",
    "https://archive.ics.uci.edu/ml/datasets/Census+Income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "role = get_execution_role()\n",
    "\n",
    "region = boto3.Session().region_name\n",
    "\n",
    "# Enter the s3 bucket and path where you want to store the training and test data\n",
    "bucket = 'bucket'\n",
    "prefix = 'prefix'\n",
    "bucket_path = 'https://s3-{}.amazonaws.com/{}'.format(region,bucket)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "\n",
    "# Get the training data set\n",
    "# This data was originally obtained from https://archive.ics.uci.edu/ml/datasets/Census+Income\n",
    "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/FINRAOS/CodeSamples/master/machine-learning-samples/src/main/resources/adult.data\", \"adult.data\")\n",
    "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/FINRAOS/CodeSamples/master/machine-learning-samples/src/main/resources/adult.test\", \"adult.test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of the field names for the data set\n",
    "fields = [\n",
    "    'age',\n",
    "    'workclass',\n",
    "    'fnlwgt',\n",
    "    'education',\n",
    "    'education-num',\n",
    "    'marital-status',\n",
    "    'occupation',\n",
    "    'relationship',\n",
    "    'race',\n",
    "    'sex',\n",
    "    'capital-gain',\n",
    "    'capital-loss',\n",
    "    'hours-per-week',\n",
    "    'native-country'\n",
    "]\n",
    "\n",
    "# Set indexes for categorical and continuous field types\n",
    "categoricalFieldIndexes = [1, 3, 5, 6, 7, 8, 9, 13]\n",
    "continuousFieldIndexes = [0, 2, 4, 10, 11, 12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the data set into a dataframe and format it\n",
    "def load_and_format_data(csv_name):\n",
    "    df = pd.read_csv(csv_name, header=None, names=fields + ['label'])\n",
    "\n",
    "    df = df.reindex(columns=['label'] + fields)\n",
    "\n",
    "    df.replace(regex='^ ', value = '', inplace=True)\n",
    "    df.replace({'label' : '\\.$'}, {'label' : ''}, regex=True, inplace=True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Load both the training and test data set\n",
    "train_data = load_and_format_data('adult.data')\n",
    "test_data = load_and_format_data('adult.test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeField(field_names):\n",
    "    for field_name in field_names:\n",
    "        index = fields.index(field_name)\n",
    "        fields.remove(field_name)\n",
    "        \n",
    "        updateIndexes(categoricalFieldIndexes, index)\n",
    "        updateIndexes(continuousFieldIndexes, index)\n",
    "        \n",
    "        train_data.drop(columns=[field_name], inplace=True)\n",
    "        test_data.drop(columns=[field_name], inplace=True)\n",
    "\n",
    "def updateIndexes(indexes, removeIndex):\n",
    "    loc = 0\n",
    "    for i in range(0, len(indexes)):\n",
    "        index = indexes[loc]\n",
    "        if index == removeIndex:\n",
    "            indexes.remove(removeIndex)\n",
    "            loc = loc - 1\n",
    "        elif index > removeIndex:\n",
    "            indexes[loc] = index - 1\n",
    "        loc = loc + 1\n",
    "        \n",
    "#removeField(['fnlwgt', 'education-num', 'relationship'])\n",
    "\n",
    "print(fields)\n",
    "print(categoricalFieldIndexes)\n",
    "print(continuousFieldIndexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display first ten rows of training set\n",
    "train_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary to store the mapping of categorical text values to numerical index values\n",
    "def get_category_index_map(column_names):\n",
    "    category_indexes = {}\n",
    "\n",
    "    for x in column_names:\n",
    "        categories = set(train_data[x].astype('category').cat.categories.tolist() + test_data[x].astype('category').cat.categories.tolist())\n",
    "        category_indexes[x] = {k:v for k, v in list(zip(categories, range(0, len(categories))))}\n",
    "\n",
    "    return category_indexes\n",
    "\n",
    "category_index_map = get_category_index_map(['label'] + [fields[x] for x in categoricalFieldIndexes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert categorical features containing text to numerical index values in the dataframe\n",
    "train_data.replace(category_index_map, inplace=True)\n",
    "test_data.replace(category_index_map, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display first ten rows of training set after data conversion\n",
    "train_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display first ten rows of test set without the label column\n",
    "test_data.drop(columns=['label']).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export dataframes to CSV (test data set should not contain the label)\n",
    "train_data.to_csv(path_or_buf='train.csv', header=None, index=False)\n",
    "test_data.drop(columns=['label']).to_csv(path_or_buf='test.csv', header=None, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload CSV files to S3\n",
    "for x in ['train', 'test']:\n",
    "    key = '{}/{}/data.csv'.format(prefix, x)\n",
    "    boto3.Session().resource('s3').Bucket(bucket).Object(key).upload_file('{}.csv'.format(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "\n",
    "from sagemaker.amazon.amazon_estimator import get_image_uri\n",
    "\n",
    "container = get_image_uri(boto3.Session().region_name, 'xgboost', '0.90-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_loc = 's3://{}/{}/{}'.format(bucket, prefix, 'train')\n",
    "\n",
    "s3_output_location = 's3://{}/{}/{}'.format(bucket, prefix, 'xgboost_model_sdk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model = sagemaker.estimator.Estimator(container,\n",
    "                                         role, \n",
    "                                         train_instance_count=1, \n",
    "                                         train_instance_type='ml.m4.xlarge',\n",
    "                                         train_volume_size = 5,\n",
    "                                         output_path=s3_output_location,\n",
    "                                         sagemaker_session=sagemaker.Session())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model.set_hyperparameters(objective = \"multi:softmax\",\n",
    "                              num_class = 2,\n",
    "                              num_round = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_channel = sagemaker.session.s3_input(train_data_loc, content_type='text/csv')\n",
    "\n",
    "data_channels = {'train': train_channel}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model.fit(inputs=data_channels, logs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run batch transform job\n",
    "batch_input = 's3://{}/{}/test/data.csv'.format(bucket, prefix)\n",
    "\n",
    "batch_output = 's3://{}/{}/batch-inference'.format(bucket, prefix)\n",
    "\n",
    "transformer = xgb_model.transformer(instance_count=1, instance_type='ml.m4.xlarge', output_path=batch_output)\n",
    "\n",
    "transformer.transform(data=batch_input, data_type='S3Prefix', content_type='text/csv', split_type='Line')\n",
    "\n",
    "transformer.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = boto3.resource('s3')\n",
    "\n",
    "s3.Bucket(bucket).download_file(prefix + '/batch-inference/data.csv.out',  'batch_results')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "with open('batch_results') as f:\n",
    "    results = f.readlines()\n",
    "    \n",
    "count = 0\n",
    "\n",
    "# Check the batch transform results against the test data\n",
    "for j in range (0, len(test_data['label'])):\n",
    "    result = int(re.sub('.0$', '', results[j].rstrip()))\n",
    "    \n",
    "    if test_data['label'][j] != result:\n",
    "        count = count + 1\n",
    "    \n",
    "print('Test error rate: {}'.format(count / len(test_data['label'])))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
